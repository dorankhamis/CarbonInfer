{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "artificial-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: latin-1 -*-\n",
    "\n",
    "# Python script to derive namelists\n",
    "\n",
    "# Garry Hayman\n",
    "# UK Centre for Ecology & Hydrology\n",
    "# November 2022\n",
    "\n",
    "# Import standard python modules\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import data_netCDF\n",
    "import write_netCDF_py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medical-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SITE_CODES = [ \\\n",
    "        #\"LBA-BAN\",  \"LBA-K34\",  \"LBA-K83\",  \"LBA-RJA\",  \"LBA-K67\", \\\n",
    "        #\"LBA-K77\",  \"LBA-FNS\",  \"LBA-PDG\", \\ \n",
    "        #\"NEO-SCBI\", \"NEO-ABBY\", \"NEO-CPER\", \"NEO-BLAN\", \"NEO-BART\", \\\n",
    "        \"AT-Neu\", \"AU-Fog\", \"BE-Vie\", \"BR-Sa1\", \"BR-Sa3\", \"CA-Oas\", \"CG-Tch\", \"CH-Cha\", \"CH-Oe1\", \"CH-Oe2\", \\\n",
    "        \"CN-Cha\", \"CN-Cng\", \"CN-Dan\", \"CN-Din\", \"CN-Du2\", \"CN-Du3\", \"CN-HaM\", \"CN-Ha2\", \"CN-Qia\", \"CN-Sw2\", \\\n",
    "        \"CZ-wet\", \"DE-Akm\", \"DE-SfN\", \"DE-Spw\", \"DE-Tha\", \"DE-Zrk\", \"GL-NuF\", \"GL-ZaF\", \"ES-Amo\", \"FI-Hyy\", \\\n",
    "        \"FI-Lom\", \"FR-Gri\", \"FR-Pue\", \"GF-Guy\", \"IT-CA1\", \"IT-Col\", \"IT-Cpz\", \"IT-Cp2\", \"IT-Noe\", \"IT-Ren\", \\\n",
    "        \"IT-SRo\", \"SJ-Adv\", \"RU-Che\", \"RU-SkP\", \"SD-Dem\", \"SE-St1\", \\\n",
    "        \"UK-AMo\", \"UK-Arn\", \"UK-Bam\", \"UK-BBB\", \"UK-BBC\", \"UK-BnB\", \"UK-CLs\", \"UK-Cst\", \"UK-Dke\", \"UK-DkF\", \\\n",
    "        \"UK-EBu\", \"UK-Ech\", \"UK-EHd\", \"UK-ESa\", \"UK-GaB\", \"UK-Gnn\", \"UK-Gri\", \"UK-Gst\", \"UK-GtF\", \"UK-Gwr\", \\\n",
    "        \"UK-Ham\", \"UK-Har\", \"UK-Her\", \"UK-LBT\", \"UK-Lns\", \"UK-MrH\", \"UK-Myg\", \"UK-PL1\", \"UK-PL2\", \"UK-PL3\", \\\n",
    "        \"UK-Png\", \"UK-Po1\", \"UK-Po2\", \"UK-Po3\", \"UK-Pob\", \"UK-Rdm\", \"UK-Rsh\", \"UK-Stm\", \"UK-Swt\", \"UK-Tad\", \\\n",
    "        \"UK-WdC\", \"UK-Wdd\", \"UK-Wot\", \\\n",
    "        \"US-Atq\", \"US-Blo\", \"US-Ha1\", \"US-Ivo\", \"US-Los\", \"US-MMS\", \"US-Myb\", \"US-Ne1\", \"US-Ne2\", \"US-Ne3\", \\\n",
    "        \"US-ORv\", \"US-PFa\", \"US-SRG\", \"US-SRM\", \"US-Ton\", \"US-Tw1\", \"US-Tw4\", \"US-UMB\", \"US-Var\", \"US-WCr\", \\\n",
    "        \"US-Whs\", \"US-Wkg\", \"US-WPT\", \"ZA-Kru\", \"ZM-Mon\"\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norwegian-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date\n",
    "# Uses the datetime module (imported as dt)\n",
    "# https://docs.python.org/2/library/datetime.html#\n",
    "\n",
    "def parse_datetime(DATE,iOPT):\n",
    "\n",
    "    # Date format YYYY-MM-DD\n",
    "    if iOPT == 1:\n",
    "        YEAR,MONTH,DAY     = int(DATE[0:4]),int(DATE[5:7]),int(DATE[8:10])\n",
    "        oDATE         = dt.datetime(YEAR,MONTH,DAY,0,0,0)\n",
    "        return YEAR,MONTH,DAY,oDATE\n",
    "\n",
    "    # Date format YYYY-MM-DD HH:MM:SS\n",
    "    elif iOPT == 2:\n",
    "        YEAR,MONTH,DAY     = int(DATE[0:4]),int(DATE[5:7]),int(DATE[8:10])\n",
    "        HOUR,MINUTE,SECOND = int(DATE[11:13]),int(DATE[14:16]),int(DATE[18:19])\n",
    "        oDATE         = dt.datetime(YEAR,MONTH,DAY,HOUR,MINUTE,SECOND)\n",
    "        return YEAR,MONTH,DAY,HOUR,MINUTE,SECOND,oDATE\n",
    "\n",
    "    # Date format dd/MM/YYYY\n",
    "    if iOPT == 3:\n",
    "        YEAR,MONTH,DAY     = int(DATE[6:10]),int(DATE[3:5]),int(DATE[0:2])\n",
    "        oDATE         = dt.datetime(YEAR,MONTH,DAY,0,0,0)\n",
    "        return YEAR,MONTH,DAY,oDATE\n",
    "\n",
    "    # Date format dd/MM/YYYY HH:MM:SS\n",
    "    if iOPT == 4:\n",
    "        YEAR,MONTH,DAY     = int(DATE[6:10]),int(DATE[3:5]),int(DATE[0:2])\n",
    "        HOUR,MINUTE,SECOND = int(DATE[11:13]),int(DATE[14:16]),int(DATE[18:19])\n",
    "        oDATE         = dt.datetime(YEAR,MONTH,DAY,HOUR,MINUTE,SECOND)\n",
    "        return YEAR,MONTH,DAY,HOUR,MINUTE,SECOND,oDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined functions using the pandas module (imported as pd)\n",
    "# See https://pandas.pydata.org/docs/user_guide/index.html\n",
    "# See cheat sheet: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf \n",
    "\n",
    "# Get data from a csv file into a data frame \n",
    "def get_df_from_csv(DIR,FILE):\n",
    "    DF           = pd.read_csv(DIR+FILE)\n",
    "    return DF\n",
    "\n",
    "# Get data from an excel spreadsheet into a data frame \n",
    "def get_df_from_excel(DIR,FILE,SHEET):\n",
    "    DF           = pd.read_excel(DIR+FILE,SHEET)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flush-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined functions to convert vapour pressure deficit to humidty\n",
    "\n",
    "Tref         = 273.15\n",
    "Pref         = 101325.0\n",
    "RMM_water    = 18.0160 # molecular weight of water\n",
    "RMM_air      = 28.9660 # molecular weight of dry air\n",
    "\n",
    "def SVP_from_T(T):\n",
    "    '''Derive saturated vapour pressure (units [Pa]) for a given air temperature (units [K])'''\n",
    "    logT_Tref    = np.log10(T/Tref)\n",
    "    \n",
    "    SVP          = Pref*10**(10.79586*(1-Tref/T)-5.02808*logT_Tref+ \\\n",
    "                   1.50474*1e-4*(1.-10**(-8.29692*(T/Tref-1)))+ \\\n",
    "                   0.42873*1e-3*(10**(4.76955*(1-Tref/T))-1)-2.2195983)\n",
    "    return SVP\n",
    "\n",
    "def RH_from_VPD_T(VPD, T):\n",
    "    # VPD Units = Pa\n",
    "    # T Units = Kelvin\n",
    "    SVP          = SVP_from_T(T)\n",
    "    RH           = (1.0-(VPD/SVP))*100.0\n",
    "    return RH\n",
    "\n",
    "def RH_2_mixing_ratio(RH, P, T):\n",
    "    '''Convert relative humidity to water vapour mixing ratio'''\n",
    "    SVP          = SVP_from_T(T)\n",
    "    return (RMM_water/RMM_air)*(RH/100.0)*SVP/(P-(RH/100.0)*SVP)*1000.0\n",
    "\n",
    "def mixing_ratio_2_specific_humidity(MR_water):\n",
    "    '''Convert mixing ratio (units [kg/kg]) to specific humidity (units also [kg/kg])'''\n",
    "    return MR_water/(1.0+MR_water)\n",
    "\n",
    "def RH_2_specific_humidity(RH, P, T):\n",
    "    '''conversion from relative humidity (units %) to specific humidity (units [kg/kg])'''\n",
    "    MR_water     = RH_2_mixing_ratio(RH, P, T)\n",
    "    return mixing_ratio_2_specific_humidity(MR_water*1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decent-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_metadata(DIR, SITE_CODES, DEBUG):\n",
    "    \n",
    "    SITE_DATA    = { SITE_CODE:{ \\\n",
    "                        'site_name':'',   'site_code':'',\n",
    "                        'latitude':'',    'longitude':'',   'easting':'',     'northing':'', \\\n",
    "                        'drive_start':'', 'drive_end':'',   'drive_tstep':'', \\\n",
    "                        'jules_start':'', 'jules_end':'',   'jules_tstep':'', \\\n",
    "                        'lai_start':'',   'lai_end':'',     'lai_tstep':'',   \\\n",
    "                        'sthuf_start':'', 'sthuf_end':'',   'sthuf_tstep':'', \\\n",
    "                        'presc_data':'',  'presc_levels':'','top_mod_opt':'', \\\n",
    "                        'file_top':'',    'file_fracs':'',  'file_soil':'',   \\\n",
    "                        'file_drive':'',  'file_flux':'',   'file_lai':''   \\\n",
    "                               } for SITE_CODE in SITE_CODES }\n",
    "\n",
    "    # Get metadata\n",
    "    DF_META          = get_df_from_excel(DIR, 'MotherShip_Site_Data_202211.xlsx', 'Site_Meta')\n",
    "    DF_ANCIL         = get_df_from_excel(DIR, 'MotherShip_Site_Data_202211.xlsx', 'Site_Ancil')\n",
    "    DF_DRIVE         = get_df_from_excel(DIR, 'MotherShip_Site_Data_202211.xlsx', 'Site_Drive')\n",
    "    \n",
    "    # Convert time to 'YYYY-MM-DD HH:MM:SS'\n",
    "    DF_DRIVE['JULES Start'] = DF_DRIVE['JULES Start'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    DF_DRIVE['JULES End']   = DF_DRIVE['JULES End'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    DF_DRIVE['Drive Start'] = DF_DRIVE['Drive Start'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    DF_DRIVE['Drive End']   = DF_DRIVE['Drive End'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    DF_DRIVE['STHUF Start'] = DF_DRIVE['STHUF Start'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    DF_DRIVE['STHUF End']   = DF_DRIVE['STHUF End'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    DF_DRIVE['LAI Start']   = DF_DRIVE['LAI Start'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    DF_DRIVE['LAI End']     = DF_DRIVE['LAI End'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Extract metadata for sites of interest\n",
    "    for iSITE, SITE_CODE in enumerate(SITE_CODES):\n",
    "        if DEBUG == 'Y':\n",
    "            print(SITE_CODE)\n",
    "\n",
    "        INDEX        = np.where(DF_META['Site Code'].values == SITE_CODE)[0]\n",
    "        SITE_DATA[SITE_CODE]['site_code'] = SITE_CODE.replace('-','_')\n",
    "        SITE_DATA[SITE_CODE]['site_name'] = DF_META['Site Name'][INDEX].values[0]\n",
    "        SITE_DATA[SITE_CODE]['latitude']  = float(DF_META['Site Latitude'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['longitude'] = float(DF_META['Site Longitude'][INDEX].values[0])\n",
    "\n",
    "        INDEX        = np.where(DF_ANCIL['Site Code'].values == SITE_CODE)[0]\n",
    "        SITE_DATA[SITE_CODE]['file_fracs']  = str(DF_ANCIL['File Frac'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['file_soil']   = str(DF_ANCIL['File Soil'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['file_top']    = str(DF_ANCIL['File Top'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['top_mod_opt'] = float(DF_ANCIL['TopModel Option'][INDEX].values[0])\n",
    "        \n",
    "        INDEX        = np.where(DF_DRIVE['Site Code'].values == SITE_CODE)[0]\n",
    "        SITE_DATA[SITE_CODE]['file_drive']  = str(DF_DRIVE['File Met Data'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['file_flux']   = str(DF_DRIVE['File Flux Data'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['file_lai']    = str(DF_DRIVE['File LAI Data'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['jules_start'] = str(DF_DRIVE['JULES Start'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['jules_end']   = str(DF_DRIVE['JULES End'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['jules_tstep'] = '%0d' % (DF_DRIVE['JULES Tstep'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['drive_start'] = str(DF_DRIVE['Drive Start'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['drive_end']   = str(DF_DRIVE['Drive End'][INDEX].values[0])\n",
    "        SITE_DATA[SITE_CODE]['drive_tstep'] = '%0d' % (DF_DRIVE['Drive Tstep'][INDEX].values[0])\n",
    "\n",
    "        SITE_DATA[SITE_CODE]['presc_data']  = '%0d' % (DF_DRIVE['Prescribed Data'][INDEX].values[0])\n",
    "        if int(SITE_DATA[SITE_CODE]['presc_data']) >= 1:\n",
    "            SITE_DATA[SITE_CODE]['sthuf_start'] = str(DF_DRIVE['STHUF Start'][INDEX].values[0])\n",
    "            SITE_DATA[SITE_CODE]['sthuf_end']   = str(DF_DRIVE['STHUF End'][INDEX].values[0])\n",
    "            SITE_DATA[SITE_CODE]['sthuf_tstep'] = '%0d' % (DF_DRIVE['STHUF Tstep'][INDEX].values[0])\n",
    "            SITE_DATA[SITE_CODE]['presc_levels']= DF_DRIVE['Prescribed Levels'][INDEX].values[0]\n",
    "        \n",
    "        if int(SITE_DATA[SITE_CODE]['presc_data']) >= 2:\n",
    "            SITE_DATA[SITE_CODE]['lai_start']   = str(DF_DRIVE['LAI Start'][INDEX].values[0])\n",
    "            SITE_DATA[SITE_CODE]['lai_end']     = str(DF_DRIVE['LAI End'][INDEX].values[0])\n",
    "            SITE_DATA[SITE_CODE]['lai_tstep']   = '%0d' % (DF_DRIVE['LAI Tstep'][INDEX].values[0])\n",
    "\n",
    "    # Convert latitudes and longitudes to OSGB36 grid for UK sites        \n",
    "    for iSITE, SITE_CODE in enumerate(SITE_CODES):\n",
    "        if 'UK' in SITE_CODE:\n",
    "            LON                = SITE_DATA[SITE_CODE]['longitude']\n",
    "            LAT                = SITE_DATA[SITE_CODE]['latitude']\n",
    "            OS_GRID            = ccrs.OSGB().transform_point( LON, LAT, ccrs.PlateCarree() )\n",
    "\n",
    "            SITE_DATA[SITE_CODE]['easting']    = OS_GRID[0]\n",
    "            SITE_DATA[SITE_CODE]['northing']   = OS_GRID[1]\n",
    "            print('Metadata: ',SITE_CODE, LON, LAT, \\\n",
    "                 SITE_DATA[SITE_CODE]['easting'], SITE_DATA[SITE_CODE]['northing'])\n",
    "\n",
    "    return SITE_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empty-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_namelist_ancil(DIR, SITE_CODE, SITE_DATA, DEBUG):\n",
    "    \n",
    "    NML_JULES = [ \\\n",
    "        \"# automatically generated file: do not edit manually\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_frac]\",\n",
    "        \"file='$CYLC_SUITE_RUN_DIR/ancil/tilefracs/FILE_SITE_FRACS'\",\n",
    "        \"read_from_dump=.false.\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_latlon]\",\n",
    "        \"const_val=sLAT,sLON\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_soil_props]\",\n",
    "        \"!!const_val=10*0.0\",\n",
    "        \"const_z=.true.\",\n",
    "        \"file='$CYLC_SUITE_RUN_DIR/ancil/soil/FILE_SITE_SOIL'\",\n",
    "        \"nvars=10\",\n",
    "        \"read_from_dump=.false.\",\n",
    "        \"tpl_name=10*''\",\n",
    "        \"use_file=10*.true.\",\n",
    "        \"var='b','sathh','satcon','sm_sat','sm_crit','sm_wilt','hcap',\",\n",
    "        \"   ='hcon','albsoil', 'clay'\",\n",
    "        \"var_name='','','','','','','','','',''\",\n",
    "        \"\",    \n",
    "        \"[namelist:jules_top]\",\n",
    "        \"const_val=1.0,8.066711,2.067616\",\n",
    "        \"file='FILE_TOP'\",\n",
    "        \"nvars=3\",\n",
    "        \"read_from_dump=.false.\",\n",
    "        \"tpl_name='','',''\",\n",
    "        \"use_file=.false.,.true.,.true.\",\n",
    "        \"var='fexp','ti_mean','ti_sig'\",\n",
    "        \"var_name='field900_2','field900','field900_1'\",\n",
    "        \"\"\n",
    "                ]\n",
    "\n",
    "    NML_SOIL  = [ \\\n",
    "        \"[namelist:jules_soil]\\n\",\n",
    "        \"l_vg_soil=.true.\\n\",\n",
    "        \"\\n\",\n",
    "        \"[namelist:jules_soil_props]\",\n",
    "                ]\n",
    "    \n",
    "    # Writing output\n",
    "    NML_FILE_OUT       = DIR+'app/jules/opt/rose-app-ancil-'+SITE_DATA[SITE_CODE]['site_code']+'.conf'\n",
    "    print(\"Writing to \"+NML_FILE_OUT)\n",
    "    NML_FID            = open(NML_FILE_OUT,'w')\n",
    "\n",
    "    for LINE in NML_JULES:\n",
    "        OUTLINE            = LINE\n",
    "        \n",
    "        if \"namelist:jules_soil_props\" in LINE and 'UK' in SITE_CODE:\n",
    "            OUTLINE            = ''\n",
    "            for LINE_SOIL in NML_SOIL:\n",
    "                OUTLINE           = OUTLINE+LINE_SOIL\n",
    "\n",
    "        if \"FILE_SITE_FRACS\" in LINE:\n",
    "            FILE_SITE_FRACS    = SITE_DATA[SITE_CODE]['file_fracs']\n",
    "            OUTLINE            = OUTLINE.replace(\"FILE_SITE_FRACS\",FILE_SITE_FRACS) \n",
    "\n",
    "        if \"FILE_SITE_SOIL\" in LINE:\n",
    "            if 'UK' in SITE_CODE:\n",
    "                FILE_SITE_SOIL     = SITE_DATA[SITE_CODE]['file_soil']+\"/\"+SITE_CODE.replace(\"-\",\"_\")+\"_soil_\"+ \\\n",
    "                                     SITE_DATA[SITE_CODE]['file_soil']+\"_vg.dat\"\n",
    "            else:\n",
    "                FILE_SITE_SOIL     = SITE_DATA[SITE_CODE]['file_soil']+\"/\"+SITE_CODE.replace(\"-\",\"_\")+\"_soil_\"+ \\\n",
    "                                     SITE_DATA[SITE_CODE]['file_soil']+\".dat\"\n",
    "                \n",
    "            OUTLINE            = OUTLINE.replace(\"FILE_SITE_SOIL\",FILE_SITE_SOIL) \n",
    "\n",
    "        if \"FILE_SOIL\" in LINE:\n",
    "            FILE_SOIL          = SITE_DATA[SITE_CODE]['file_soil']\n",
    "            OUTLINE            = OUTLINE.replace(\"FILE_SOIL\",FILE_SOIL) \n",
    "\n",
    "        if \"FILE_TOP\" in LINE:\n",
    "            TOP_MOD_OPT        = int(SITE_DATA[SITE_CODE]['top_mod_opt'])\n",
    "            if TOP_MOD_OPT == 1:\n",
    "                FILE_TOP           = \"dummy.dat\"\n",
    "            if TOP_MOD_OPT == 2:\n",
    "                FILE_TOP           = \"$CYLC_SUITE_RUN_DIR/ancil/topmodel/\"+SITE_DATA[SITE_CODE]['file_top']\n",
    "            OUTLINE            = OUTLINE.replace(\"FILE_TOP\",FILE_TOP) \n",
    "\n",
    "        if \"sLAT,sLON\" in LINE:\n",
    "            sLAT               = '%.4f' % SITE_DATA[SITE_CODE]['latitude']\n",
    "            sLON               = '%.4f' % SITE_DATA[SITE_CODE]['longitude']\n",
    "            OUTLINE            = OUTLINE.replace(\"sLAT,sLON\",sLAT+\",\"+sLON)\n",
    "            \n",
    "        NML_FID.write(OUTLINE+'\\n')\n",
    "            \n",
    "    NML_FID.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competent-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_namelist_drive(DIR, SITE_CODE, SITE_DATA, DEBUG):\n",
    "    \n",
    "    NML_JULES = [ \\\n",
    "        \"# automatically generated file: do not edit manually\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_drive]\",\n",
    "        \"data_end='DRIVE_END'\",\n",
    "        \"data_period=DRIVE_TSTEP\",\n",
    "        \"data_start='DRIVE_START'\",\n",
    "        \"file='$FLUXNET2015_DRIVE_DIR/SITE_CODE-met.dat'\",\n",
    "        \"interp=7*'nf'\",\n",
    "        \"var='t','sw_down','lw_down','q','pstar','precip','wind'\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_time]\",\n",
    "        \"timestep_len=JULES_TSTEP\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_time]\",\n",
    "        \"l_360=.false.\",\n",
    "        \"l_leap=.true.\"\n",
    "                      ]\n",
    "\n",
    "    # Writing output\n",
    "    NML_FILE_OUT       = DIR+'app/jules/opt/rose-app-drive-'+SITE_DATA[SITE_CODE]['site_code']+'.conf'\n",
    "    print(\"Writing to \"+NML_FILE_OUT)\n",
    "    NML_FID            = open(NML_FILE_OUT,'w')\n",
    "\n",
    "    for LINE in NML_JULES:\n",
    "        OUTLINE            = LINE \n",
    "\n",
    "        if \"SITE_CODE\" in LINE:\n",
    "            SITE_CODE_U        = SITE_DATA[SITE_CODE]['site_code']\n",
    "            OUTLINE            = OUTLINE.replace(\"SITE_CODE\",SITE_CODE_U) \n",
    "        if \"DRIVE_START\" in LINE:\n",
    "            DRIVE_START        = SITE_DATA[SITE_CODE]['drive_start']\n",
    "            OUTLINE            = OUTLINE.replace(\"DRIVE_START\",DRIVE_START) \n",
    "        if \"DRIVE_END\" in LINE:\n",
    "            DRIVE_END          = SITE_DATA[SITE_CODE]['drive_end']\n",
    "            OUTLINE            = OUTLINE.replace(\"DRIVE_END\",DRIVE_END) \n",
    "        if \"DRIVE_TSTEP\" in LINE:\n",
    "            DRIVE_TSTEP        = SITE_DATA[SITE_CODE]['drive_tstep']\n",
    "            OUTLINE            = OUTLINE.replace(\"DRIVE_TSTEP\",DRIVE_TSTEP) \n",
    "        if \"JULES_TSTEP\" in LINE:\n",
    "            JULES_TSTEP        = SITE_DATA[SITE_CODE]['drive_tstep']\n",
    "            OUTLINE            = OUTLINE.replace(\"JULES_TSTEP\",JULES_TSTEP) \n",
    "            \n",
    "        NML_FID.write(OUTLINE+'\\n')\n",
    "            \n",
    "    NML_FID.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finished-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_namelist_presc_sthuf(DIR, SITE_CODE, SITE_DATA, DEBUG):\n",
    "    \n",
    "    NML_JULES = [ \\\n",
    "        \"# automatically generated file: do not edit manually\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_prescribed_dataset(2)]\",\n",
    "        \"data_end='STHUF_END'\",\n",
    "        \"data_period=STHUF_TSTEP\",\n",
    "        \"data_start='STHUF_START'\",\n",
    "        \"file='$STHUF_DIR/prescribed_sthuf_SITE_CODE.txt'\",\n",
    "        \"interp='nf'\",\n",
    "        \"is_climatology=.false.\",\n",
    "        \"!!nfiles=0\",\n",
    "        \"nvars=1\",\n",
    "        \"prescribed_levels=PRESC_LEVELS\",\n",
    "        \"read_list=.false.\",\n",
    "        \"tpl_name=''\",\n",
    "        \"var='sthuf'\",\n",
    "        \"var_name='sthuf'\"\n",
    "                      ]\n",
    "\n",
    "    # Writing output\n",
    "    NML_FILE_OUT       = DIR+'app/jules/opt/rose-app-presc-sthuf-'+SITE_DATA[SITE_CODE]['site_code']+'.conf'\n",
    "    print(\"Writing to \"+NML_FILE_OUT)\n",
    "    NML_FID            = open(NML_FILE_OUT,'w')\n",
    "\n",
    "    for LINE in NML_JULES:\n",
    "        OUTLINE            = LINE \n",
    "\n",
    "        if \"SITE_CODE\" in LINE:\n",
    "            #SITE_CODE_U        = SITE_DATA[SITE_CODE]['site_code']\n",
    "            #OUTLINE            = OUTLINE.replace(\"SITE_CODE\",SITE_CODE_U)\n",
    "            OUTLINE            = OUTLINE.replace(\"SITE_CODE\",SITE_CODE)\n",
    "        if \"STHUF_START\" in LINE:\n",
    "            STHUF_START        = SITE_DATA[SITE_CODE]['sthuf_start']\n",
    "            OUTLINE            = OUTLINE.replace(\"STHUF_START\",STHUF_START) \n",
    "        if \"STHUF_END\" in LINE:\n",
    "            STHUF_END          = SITE_DATA[SITE_CODE]['sthuf_end']\n",
    "            OUTLINE            = OUTLINE.replace(\"STHUF_END\",STHUF_END) \n",
    "        if \"STHUF_TSTEP\" in LINE:\n",
    "            STHUF_TSTEP        = SITE_DATA[SITE_CODE]['sthuf_tstep']\n",
    "            OUTLINE            = OUTLINE.replace(\"STHUF_TSTEP\",STHUF_TSTEP) \n",
    "        if \"PRESC_LEVELS\" in LINE:\n",
    "            PRESC_LEVELS       = SITE_DATA[SITE_CODE]['presc_levels']\n",
    "            OUTLINE            = OUTLINE.replace(\"PRESC_LEVELS\",PRESC_LEVELS[1:-1]) \n",
    "            \n",
    "        NML_FID.write(OUTLINE+'\\n')\n",
    "            \n",
    "    NML_FID.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coated-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_namelist_presc_lai(DIR, SITE_CODE, SITE_DATA, DEBUG):\n",
    "    \n",
    "    NML_JULES = [ \\\n",
    "        \"# automatically generated file: do not edit manually\",\n",
    "        \"\",\n",
    "        \"[namelist:jules_prescribed_dataset(3)]\",\n",
    "        \"data_end='LAI_END'\",\n",
    "        \"data_period=LAI_TSTEP\",\n",
    "        \"data_start='LAI_START'\",\n",
    "        \"file='$LAI_DIR/LAI_FILE.txt'\",\n",
    "        \"interp='nf'\",\n",
    "        \"is_climatology=.false.\",\n",
    "        \"!!nfiles=0\",\n",
    "        \"nvars=1\",\n",
    "        \"read_list=.false.\",\n",
    "        \"tpl_name=''\",\n",
    "        \"var='lai'\",\n",
    "        \"var_name=''\"\n",
    "                      ]\n",
    "\n",
    "    # Writing output\n",
    "    NML_FILE_OUT       = DIR+'app/jules/opt/rose-app-presc-lai-'+SITE_DATA[SITE_CODE]['site_code']+'.conf'\n",
    "    print(\"Writing to \"+NML_FILE_OUT)\n",
    "    NML_FID            = open(NML_FILE_OUT,'w')\n",
    "\n",
    "    for LINE in NML_JULES:\n",
    "        OUTLINE            = LINE \n",
    "\n",
    "        if \"LAI_FILE\" in LINE:\n",
    "            LAI_FILE           = SITE_DATA[SITE_CODE]['file_lai']\n",
    "            OUTLINE            = OUTLINE.replace(\"LAI_FILE\",LAI_FILE) \n",
    "        if \"LAI_START\" in LINE:\n",
    "            LAI_START        = SITE_DATA[SITE_CODE]['lai_start']\n",
    "            OUTLINE            = OUTLINE.replace(\"LAI_START\",LAI_START) \n",
    "        if \"LAI_END\" in LINE:\n",
    "            LAI_END          = SITE_DATA[SITE_CODE]['lai_end']\n",
    "            OUTLINE            = OUTLINE.replace(\"LAI_END\",LAI_END) \n",
    "        if \"LAI_TSTEP\" in LINE:\n",
    "            LAI_TSTEP        = SITE_DATA[SITE_CODE]['lai_tstep']\n",
    "            OUTLINE            = OUTLINE.replace(\"LAI_TSTEP\",LAI_TSTEP) \n",
    "            \n",
    "        NML_FID.write(OUTLINE+'\\n')\n",
    "            \n",
    "    NML_FID.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "particular-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_var_info(DIR, ALL_SITE_CODES, INFO_UK_SITES, SITE_DATA, DEBUG):\n",
    "    \n",
    "    VAR_START = [ \\\n",
    "        '',\n",
    "        '# n.b. change IT_Cp2 presc_avail to 1 when prescribed_sthuf_IT-Cp2.txt goes in to next data version',\n",
    "        '',\n",
    "        '{%- set site_info = {',\n",
    "        '        \"LBA_BAN\" : {\"run_dates\" : [\"2004-01-02\", \"2006-10-31\"], \"presc_avail\" : 2},',\n",
    "        '        \"LBA_K34\" : {\"run_dates\" : [\"2003-01-02\", \"2005-10-15\"], \"presc_avail\" : 2},',\n",
    "        '        \"LBA_K83\" : {\"run_dates\" : [\"2001-01-02\", \"2003-08-12\"], \"presc_avail\" : 2},',\n",
    "        '        \"LBA_RJA\" : {\"run_dates\" : [\"2000-02-03\", \"2002-09-13\"], \"presc_avail\" : 2},',\n",
    "        '        \"LBA_K67\" : {\"run_dates\" : [\"2002-01-02\", \"2003-11-18\"], \"presc_avail\" : 2},',\n",
    "        '        \"LBA_K77\" : {\"run_dates\" : [\"2001-01-02\", \"2005-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"LBA_FNS\" : {\"run_dates\" : [\"1999-01-02\", \"2001-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"LBA_PDG\" : {\"run_dates\" : [\"2002-01-02\", \"2003-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_SCBI\": {\"run_dates\" : [\"2017-03-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_ABBY\": {\"run_dates\" : [\"2017-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_CPER\": {\"run_dates\" : [\"2016-12-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_BLAN\": {\"run_dates\" : [\"2017-03-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_BART\": {\"run_dates\" : [\"2017-03-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_GUAN\": {\"run_dates\" : [\"2018-08-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_HARV\": {\"run_dates\" : [\"2017-09-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_TALL\": {\"run_dates\" : [\"2017-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_WREF\": {\"run_dates\" : [\"2018-06-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_CLBJ\": {\"run_dates\" : [\"2017-12-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_KONZ\": {\"run_dates\" : [\"2017-09-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_NIWO\": {\"run_dates\" : [\"2017-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_ONAQ\": {\"run_dates\" : [\"2017-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_ORNL\": {\"run_dates\" : [\"2017-09-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_BONA\": {\"run_dates\" : [\"2017-11-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_OSBS\": {\"run_dates\" : [\"2017-03-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_PUUM\": {\"run_dates\" : [\"2019-06-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_SJER\": {\"run_dates\" : [\"2018-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_TOOL\": {\"run_dates\" : [\"2017-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_YELL\": {\"run_dates\" : [\"2018-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_SRER\": {\"run_dates\" : [\"2017-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_UNDE\": {\"run_dates\" : [\"2017-03-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "        '        \"NEO_WOOD\": {\"run_dates\" : [\"2017-10-02\", \"2021-12-31\"], \"presc_avail\" : 0},',\n",
    "                      ]\n",
    "    \n",
    "    VAR_END   = [ \\\n",
    "        '     }%}',\n",
    "        '',\n",
    "        '     {%- set wetland_sites = [\"LBA_BAN\", \"AU-Fog\", \"CN-Ha2\",',\n",
    "        '             \"CZ_wet\", \"DE_Akm\", \"DE_SfN\", \"DE_Spw\", \"DE_Zrk\", \"DK_NuF\", \"DK_ZaF\", \"FI_Lom\",',\n",
    "        '             \"NO_Adv\", \"RU-Che\", \"SE_St1\", \"US_Atq\", \"US_Ivo\", \"US_Los\", \"US_Myb\", \"US_ORv\", \"US_Tw1\",',\n",
    "        '             \"US_Tw4\", \"US_WPT\"]',\n",
    "        '      %}',\n",
    "        '',\n",
    "        '     {%- set deposition_sites = [\"CH_Oe1\", \"CH_Oe2\", \"FI_Hyy\", \"FR_Gri\", \"IT_Cpz\", \"IT_Cp2\", \"US_Ha1\"]',\n",
    "        '      %}',\n",
    "        '',\n",
    "        '     {%- set uk_flux_sites = XXXX %}',\n",
    "        ''\n",
    "                      ]\n",
    "\n",
    "    # Writing output\n",
    "    VAR_FILE_OUT       = DIR+'var/info.inc'\n",
    "    print(\"Writing to \"+VAR_FILE_OUT)\n",
    "    VAR_FID            = open(VAR_FILE_OUT,'w')\n",
    "\n",
    "    for LINE in VAR_START:\n",
    "        VAR_FID.write(LINE+'\\n')\n",
    "\n",
    "    for SITE_CODE in ALL_SITE_CODES:\n",
    "        RUN_START          = SITE_DATA[SITE_CODE]['jules_start'][:10]\n",
    "        RUN_END            = SITE_DATA[SITE_CODE]['jules_end'][:10]\n",
    "        PRESC_CODE         = SITE_DATA[SITE_CODE]['presc_data']\n",
    "        \n",
    "        OUTLINE            = '        \"'+SITE_CODE.replace(\"-\",\"_\")+'\"  : {\"run_dates\" : [\"'+ \\\n",
    "            RUN_START+'\", \"'+RUN_END+'\"], \"presc_avail\" : '+PRESC_CODE+'},'\n",
    "\n",
    "        VAR_FID.write(OUTLINE+'\\n')\n",
    "        \n",
    "    UK_SITES           = '['\n",
    "    for SITE_CODE in INFO_UK_SITES:\n",
    "        UK_SITES           = UK_SITES+'\"'+SITE_CODE.replace('-','_')+'\", '\n",
    "    UK_SITES           = UK_SITES[0:-2]+']'\n",
    "    \n",
    "    for LINE in VAR_END:\n",
    "        if 'XXXX' in LINE:\n",
    "            VAR_FID.write(LINE.replace('XXXX',UK_SITES)+'\\n')\n",
    "        else:\n",
    "            VAR_FID.write(LINE+'\\n')\n",
    "\n",
    "    VAR_FID.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "juvenile-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_ancil_soil_uk(SOIL_MODEL, VARS_OUT, DEBUG):\n",
    "    \n",
    "    # Get soil properties from CHESS data\n",
    "    DIR_CHESS     = '/prj/chess/data/1km/v1.2/ancil_uncompressed/'\n",
    "    FILE_TEXTURE  = 'chess_soil_texture_1km.nc'\n",
    "\n",
    "    # Soil and grid variables\n",
    "    if SOIL_MODEL == 'BC':\n",
    "        print(''); print('Soil parameters: Brooks & Corey')\n",
    "        FILE_SOIL     = 'chess_soilparams_hwsd_bc.nc'\n",
    "        SOIL_VARS_IN  = ['b', 'sathh', 'satcon', 'vsat', 'vcrit', 'vwilt', 'hcap', 'hcon' ]\n",
    "    elif SOIL_MODEL == 'VG':\n",
    "        print(''); print('Soil parameters: Van Genuchten')\n",
    "        FILE_SOIL     = 'chess_soilparams_hwsd_vg.nc'\n",
    "        SOIL_VARS_IN  = ['oneovernminusone', 'oneoveralpha', 'satcon', 'vsat', 'vcrit', 'vwilt', 'hcap', 'hcon' ]\n",
    "\n",
    "    GRID_VARS_IN  = ['x', 'y', 'lat', 'lon' ]\n",
    "\n",
    "    VARS_IN       = GRID_VARS_IN +SOIL_VARS_IN\n",
    "\n",
    "    DATA_SOIL     = { VAR:0.0 for VAR in VARS_OUT } \n",
    "    \n",
    "    # Get soil properties from CHESS data\n",
    "    for iVAR,VAR in enumerate(VARS_OUT):\n",
    "        if VAR == 'albsoil':\n",
    "            print('Albsoil')\n",
    "        elif VAR == 'clay':\n",
    "            print('Clay')\n",
    "            DIMS,DATA_SOIL[VAR] = data_netCDF.data_netCDF_array_var(DIR_CHESS+FILE_TEXTURE,VAR)\n",
    "        else:\n",
    "            print(VAR)\n",
    "            DIMS,DATA_SOIL[VAR] = data_netCDF.data_netCDF_array_var(DIR_CHESS+FILE_SOIL,VARS_IN[iVAR])\n",
    "\n",
    "    return DATA_SOIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compatible-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_ancil_soil_uk(DIR, SITE_CODE, SITE_DATA, DATA_SOIL, SOIL_VARS_OUT, SOIL_MODEL, DEBUG):\n",
    "\n",
    "    FILE_SITE_SOIL     = SITE_DATA[SITE_CODE]['file_soil']+\"/\"+SITE_CODE.replace(\"-\",\"_\")+\"_soil_\"+ \\\n",
    "                         SITE_DATA[SITE_CODE]['file_soil']+\"_\"+SOIL_MODEL+\".dat\"\n",
    "\n",
    "    iEAST              = int(SITE_DATA[SITE_CODE]['easting']/1000)\n",
    "    iNORTH             = int(SITE_DATA[SITE_CODE]['northing']/1000)\n",
    "    print(SITE_CODE, iEAST, iNORTH)\n",
    "\n",
    "    # Writing output\n",
    "    NML_FILE_OUT       = DIR+'ancil/soil/'+FILE_SITE_SOIL\n",
    "    print(\"Writing to \"+NML_FILE_OUT)\n",
    "    NML_FID            = open(NML_FILE_OUT,'w')\n",
    "\n",
    "    NML_FID.write(\"#            'b'       'sathh'      'satcon'      'sm_sat'     'sm_crit'\")\n",
    "    NML_FID.write(\"     'sm_wilt'        'hcap'        'hcon'     'albsoil'        'clay'\"+\"\\n\")\n",
    "    NML_FID.write(\"# automatically generated file: do not edit manually\"+\"\\n\")\n",
    "    \n",
    "    OUTLINE            = ''\n",
    "    for VAR in SOIL_VARS_OUT:\n",
    "\n",
    "        if VAR == 'albsoil':\n",
    "            DATA_VAR      = 0.15\n",
    "        else:\n",
    "            DATA_VAR      = DATA_SOIL[VAR][0,iNORTH,iEAST]\n",
    "\n",
    "        OUTLINE            = OUTLINE+('%14.6g' % DATA_VAR)\n",
    "\n",
    "    NML_FID.write(OUTLINE+'\\n')\n",
    "            \n",
    "    NML_FID.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "egyptian-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_ancil_top(TOP_VARS, DEBUG):\n",
    "    \n",
    "    # Get soil properties from CHESS data\n",
    "    DIR_TOP     = '/data/grp/eow/garr/Projects/MotherShip/Data/'\n",
    "    FILE_TOP    = 'HadGEM2ES_Ancil.nc'\n",
    "\n",
    "    print(''); print('Top Model parameters')\n",
    "    DATA_TOP     = { VAR:0.0 for VAR in TOP_VARS } \n",
    "    \n",
    "    # Get soil properties from CHESS data\n",
    "    for iVAR,VAR in enumerate(TOP_VARS):\n",
    "        print(VAR)\n",
    "        DIMS,DATA_TOP[VAR] = data_netCDF.data_netCDF_array_var(DIR_TOP+FILE_TOP,VAR)\n",
    "\n",
    "    return DATA_TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greenhouse-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_ancil_top(DIR, SITE_CODE, SITE_DATA, DATA_TOP, TOP_VARS, DEBUG):\n",
    "    \n",
    "    # Create filename from template\n",
    "    FILE_CDF        = SITE_CODE.replace(\"-\",\"_\")+\"_TOP.nc\"\n",
    "    DIR_CDF         = DIR+'ancil/topmodel/'\n",
    "    NETCDF          = 'netCDF4'\n",
    "    ATTRIB          = 'JULES_UK_Flux_Sites_namelist_generator.ipynb'\n",
    "    \n",
    "    VAR_META_DATA   = { \\\n",
    "                       'latitude':   {'name':'latitude',               'type':'float32', 'units':'degrees_north', \\\n",
    "                                      '_FillValue':float('NaN'),       'dependence': ['land']},                   \\\n",
    "                       'longitude':  {'name':'longitude',              'type':'float32', 'units':'degrees_east',  \\\n",
    "                                      '_FillValue':float('NaN'),       'dependence': ['land']},                   \\\n",
    "                       'field900':   {'name':'mean topographic index', 'type':'float32', 'units':' ',             \\\n",
    "                                      '_FillValue':float('NaN'),       'dependence': ['land']},                   \\\n",
    "                       'field900_1': {'name':'std topographic index',  'type':'float32', 'units':' ',             \\\n",
    "                                      '_FillValue':float('NaN'),       'dependence': ['land']},                   \\\n",
    "                      }\n",
    "\n",
    "    DIM_INFO        = [ [ 1, 'land'] ]\n",
    "    \n",
    "    VAR_INFO_ALL, VAR_DATA_ALL, VAR_DEP_ALL = [], [], []\n",
    "    \n",
    "    for VAR in TOP_VARS:\n",
    "\n",
    "        VAR_INFO_ALL.append([VAR, VAR_META_DATA[VAR]['type'], VAR_META_DATA[VAR]['units'], \\\n",
    "                             '', VAR_META_DATA[VAR]['_FillValue'], VAR_META_DATA[VAR]['name'], '', '' ])\n",
    "        VAR_DEP_ALL.append(VAR_META_DATA[VAR]['dependence'])\n",
    "\n",
    "        if VAR == 'latitude':\n",
    "            xLAT           = SITE_DATA[SITE_CODE]['latitude']\n",
    "            iLAT           = int((90.0+xLAT)/1.25)\n",
    "            VAR_DATA_ALL.append(xLAT)\n",
    "        elif VAR == 'longitude':\n",
    "            xLON           = SITE_DATA[SITE_CODE]['longitude']\n",
    "            if xLON >= 0.0:\n",
    "                iLON           = int(xLON/1.875)\n",
    "            else:\n",
    "                iLON           = int((360.0+xLON)/1.875)\n",
    "            VAR_DATA_ALL.append(xLON)\n",
    "        else:        \n",
    "            VAR_DATA_ALL.append(DATA_TOP[VAR][iLAT,iLON])\n",
    "    \n",
    "    print(SITE_CODE, xLAT, xLON, iLAT, iLON, DATA_TOP['field900'][iLAT,iLON], DATA_TOP['field900_1'][iLAT,iLON])\n",
    "    \n",
    "    print('Writing to '+DIR_CDF+FILE_CDF)\n",
    "    write_netCDF_py3.write_netCDF_multi_new4(DIR_CDF+FILE_CDF, DIM_INFO, VAR_INFO_ALL, VAR_DEP_ALL, VAR_DATA_ALL, \\\n",
    "        ATTRIB, NETCDF, DEBUG)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "coordinated-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_write_met_data(DIR_IN, DIR_OUT, SITE_CODE, SITE_DATA, DEBUG):\n",
    "    \n",
    "    # Define filename for site met data\n",
    "    # If filename = 'n/a', return\n",
    "    FILE_MET         = SITE_DATA[SITE_CODE]['file_drive']\n",
    "    if FILE_MET == \"Not_Needed\":\n",
    "        return\n",
    "    \n",
    "    Time_Step        = float(SITE_DATA[SITE_CODE]['drive_tstep'])\n",
    "    \n",
    "    # Get met data\n",
    "    DF_MET           = get_df_from_csv(DIR_IN, FILE_MET+'.csv')\n",
    "    \n",
    "    if 'FLUXNET' in FILE_MET:\n",
    "        iSTART           = 0\n",
    "        T_Name, SW_Name, LW_Name, P_Name, PR_Name, VPD_Name, RH_Name, WS_Name = \\\n",
    "            'TA_F', 'SW_IN_F', 'LW_IN_F', 'PA_F', 'P_F', 'VPD_F', 'RH', 'WS_F'\n",
    "    else:\n",
    "        iSTART           = 1 # UK data has units on second line    \n",
    "        T_Name, SW_Name, LW_Name, P_Name, PR_Name, VPD_Name, RH_Name, WS_Name = \\\n",
    "            'TA_F_MDS', 'SW_IN_F_MDS', 'LW_IN_F_MDS', 'PA_F_MDS', 'P', 'VPD_F_MDS', 'RH_F_MDS', 'WS_F_MDS'\n",
    "    \n",
    "    if DEBUG == 'Y':\n",
    "        nDATA            = 10\n",
    "    else:\n",
    "        nDATA            = len(DF_MET[T_Name])\n",
    "\n",
    "    FILE_OUT         = DIR_OUT+SITE_CODE.replace('-','_')+'-met.dat'\n",
    "    FILE_ID          = open(FILE_OUT,'w')\n",
    "    print('Writing to: '+FILE_OUT)\n",
    "    \n",
    "    for iDATA in range(iSTART,nDATA):\n",
    "        # Met data for JULES needs to be complete, use gap-filled\n",
    "        T_K       = float(DF_MET[T_Name][iDATA])+273.15 # Convert from C to K\n",
    "        SW_Down   = float(DF_MET[SW_Name][iDATA])\n",
    "        LW_Down   = float(DF_MET[LW_Name][iDATA])\n",
    "        P_Pa      = float(DF_MET[P_Name][iDATA])*1000.0 # Convert from kPa to Pa\n",
    "        Precip    = float(DF_MET[PR_Name][iDATA])\n",
    "        WS        = float(DF_MET[WS_Name][iDATA])\n",
    "        VPD       = float(DF_MET[VPD_Name][iDATA])*100.0 # Convert from hPa to Pa\n",
    "        RH_obs    = float(DF_MET[RH_Name][iDATA])\n",
    "        # Derive humidity (kg kg-1) from vapour pressure deficit\n",
    "        RH_mod    = RH_from_VPD_T(VPD, T_K)\n",
    "        Q_water   = RH_2_specific_humidity(RH_mod, P_Pa, T_K)\n",
    "\n",
    "        if DEBUG == 'Y':\n",
    "            print(iDATA, VPD, RH_mod, RH_obs, Precip, Is_Nan, ':', OUTPUT)\n",
    "\n",
    "        if np.isnan(Precip):\n",
    "            Precip    = 0.0\n",
    "            Is_Nan    = True\n",
    "        else:\n",
    "            Precip    = Precip/Time_Step\n",
    "            Is_Nan    = False\n",
    "\n",
    "        # Output\n",
    "        # (a) Surface temperature (K)\n",
    "        # (b) Downward short-wave radiation (W m-2)\n",
    "        # (c) Downward long-wave radiation (W m-2)\n",
    "        # (d) Humidity (kg kg-1)\n",
    "        # (e) Surface pressure (Pa)\n",
    "        # (f) Precipitation (convert mm per timestep to kg m-2 s-1)\n",
    "        # (g) Wind (m s-1)\n",
    "        #OUTPUT    = ('%.3f,%.4f,%.4f,%.8f,%.2f,%.8f,%.3f' % \\\n",
    "        #    (T_K, SW_Down, LW_Down, float(Q_water), P_Pa, Precip, WS))\n",
    "        OUTPUT    = ('%s,%s,%s,%s,%s,%s,%s' % \\\n",
    "            (str(T_K), str(SW_Down), str(LW_Down), str(Q_water), str(P_Pa), str(Precip), str(WS)))\n",
    "        \n",
    "        FILE_ID.write(OUTPUT+'\\n')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "subject-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_write_flux_data_iris(DIR_IN, DIR_OUT, SITE_CODE, SITE_DATA, DEBUG):\n",
    "    \n",
    "    # Define filename for site met data\n",
    "    # If filename = 'n/a', return\n",
    "    FILE_FLUX        = SITE_DATA[SITE_CODE]['file_flux']\n",
    "    if FILE_FLUX == \"Not_Needed\":\n",
    "        return\n",
    "    \n",
    "    Time_Step        = float(SITE_DATA[SITE_CODE]['drive_tstep'])\n",
    "    \n",
    "    # Get met data\n",
    "    DF_FLUX          = get_df_from_csv(DIR_IN, FILE_FLUX+'.csv')\n",
    "\n",
    "    if 'FLUXNET' in FILE_FLUX:\n",
    "        iSTART           = 0\n",
    "        os.environ['NETWORK'] = 'FLUXNET Site'\n",
    "        \n",
    "        FILE_HEADINGS_subdaily_energy  = [ \\\n",
    "            'TIMESTAMP_START', 'TIMESTAMP_END', 'G_F_MDS', 'LE_F_MDS', 'LE_CORR', \\\n",
    "            'LE_CORR_25', 'LE_CORR_75', 'LE_RANDUNC', 'H_F_MDS', 'H_CORR', \\\n",
    "            'H_CORR_25', 'H_CORR_75', 'H_RANDUNC' \\\n",
    "                                         ]\n",
    "\n",
    "        FILE_HEADINGS_subdaily_carbon = ['TIMESTAMP_START', 'TIMESTAMP_END', 'NEE_VUT_REF', \\\n",
    "            'NEE_VUT_REF_RANDUNC', 'NEE_VUT_25', 'NEE_VUT_50', 'NEE_VUT_75', \\\n",
    "            'RECO_NT_VUT_REF', 'RECO_NT_VUT_25', 'RECO_NT_VUT_50', 'RECO_NT_VUT_75', \\\n",
    "            'GPP_NT_VUT_REF', 'GPP_NT_VUT_25', 'GPP_NT_VUT_50', 'GPP_NT_VUT_75', \\\n",
    "            'RECO_DT_VUT_REF', 'RECO_DT_VUT_25', 'RECO_DT_VUT_50', 'RECO_DT_VUT_75', \\\n",
    "            'GPP_DT_VUT_REF', 'GPP_DT_VUT_25', 'GPP_DT_VUT_50', 'GPP_DT_VUT_75' \n",
    "                                         ]\n",
    "    else:\n",
    "        iSTART           = 1 # UK data has units on second line    \n",
    "        os.environ['NETWORK'] = 'UK Site'\n",
    "\n",
    "        FILE_HEADINGS_subdaily_energy  = [ \\\n",
    "            'TIMESTAMP_START', 'TIMESTAMP_END', 'G_F_MDS_1', 'G_F_MDS_2', \\\n",
    "            'LE_F_MDS', 'LE_RANDUNC', 'H_F_MDS', 'H_RANDUNC' \\\n",
    "                                         ]\n",
    "\n",
    "        FILE_HEADINGS_subdaily_carbon = ['TIMESTAMP_START', 'TIMESTAMP_END', \\\n",
    "            'NEE_VUT_REF', 'NEE_VUT_REF_RANDUNC',  'RECO_NT_VUT_REF', 'GPP_NT_VUT_REF', \\\n",
    "            'RECO_DT_VUT_REF', 'GPP_DT_VUT_REF' \\\n",
    "                                         ]\n",
    "    \n",
    "    if DEBUG == 'Y':\n",
    "        nDATA            = 10\n",
    "    else:\n",
    "        nDATA            = len(DF_FLUX['TIMESTAMP_START'])\n",
    "\n",
    "    for EWC in ['energy', 'carbon']: \n",
    "\n",
    "        FILE_INT             = DIR_IN+'subdaily_obs/'+SITE_CODE.replace('-','_')+'-'+EWC+'.dat'\n",
    "        FILE_ID              = open(FILE_INT,'w')\n",
    "        print('Writing to: '+FILE_INT)\n",
    "\n",
    "        if EWC == 'energy':\n",
    "            FILE_HEADINGS        = FILE_HEADINGS_subdaily_energy\n",
    "        elif EWC == 'carbon':\n",
    "            FILE_HEADINGS        = FILE_HEADINGS_subdaily_carbon\n",
    "            \n",
    "        for iDATA in range(iSTART,nDATA):\n",
    "            # Subdaily flux data\n",
    "\n",
    "            FIRST     = True\n",
    "            OUTPUT    = ''\n",
    "            for VAR_NAME in FILE_HEADINGS:\n",
    "                #if 'TIMESTAMP' in VAR_NAME:\n",
    "                #    DF_FLUX[VAR_NAME][iDATA] = str(DF_FLUX[VAR_NAME][iDATA])+'00'\n",
    "                if FIRST:\n",
    "                    OUTPUT    = OUTPUT+'%s' % str(DF_FLUX[VAR_NAME][iDATA])\n",
    "                    FIRST     = False\n",
    "                else:\n",
    "                    OUTPUT    = OUTPUT+',%s' % str(DF_FLUX[VAR_NAME][iDATA])\n",
    "                \n",
    "            if DEBUG == 'Y':\n",
    "                print(iDATA, OUTPUT)\n",
    "\n",
    "            FILE_ID.write(OUTPUT+'\\n')\n",
    "\n",
    "        FILE_ID.close()\n",
    "\n",
    "    os.environ['OBS_FOLDER_PRE2015'] = DIR_IN\n",
    "    os.environ['OBS_FOLDER']         = DIR_IN\n",
    "    os.environ['OBS_FOLDER_LBA']     = DIR_IN\n",
    "    import fluxnet_evaluation\n",
    "\n",
    "    UTC_OFFSET       = 0\n",
    "    fluxnet_evaluation.create_fluxnet2015_dailyUTC_files(SITE_CODE.replace('-','_'), UTC_OFFSET, DIR_OUT)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "composed-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_write_flux_data_pandas(DIR_IN, DIR_OUT, SITE_CODE, SITE_DATA, DEBUG):\n",
    "    \n",
    "    DATETIME_format  = '%Y%m%d%H%M'\n",
    "    TIME_convertfunc = lambda x: dt.datetime.strptime(x, DATETIME_format)\n",
    "    CONVERTERS       = {'TIMESTAMP_START':TIME_convertfunc,\n",
    "                        'TIMESTAMP_END':TIME_convertfunc}\n",
    "\n",
    "    VAR_NAMES        = ['GPP_NT_VUT_REF','RECO_NT_VUT_REF','NEE_VUT_REF', \\\n",
    "                        'H_F_MDS','LE_F_MDS']\n",
    "    \n",
    "    HEADER           = ['GPP', 'Reco', 'NEE', 'SH', 'LE']\n",
    "    \n",
    "    CONV_C           = 12.011*1e-06*float(60*60*24)\n",
    "    CONV_FACTORS     = [CONV_C, CONV_C, CONV_C, 1.0, 1.0]\n",
    "    \n",
    "    # Define filename for site met data\n",
    "    # If filename = 'n/a', return\n",
    "    FILE_FLUX        = SITE_DATA[SITE_CODE]['file_flux']\n",
    "    if FILE_FLUX == \"Not_Needed\":\n",
    "        return\n",
    "\n",
    "    # Need to replace TIMESTAMP_START\n",
    "    OS_CMD = \"sed -e '2s/-/# -/' < \"+DIR_IN+FILE_FLUX+'.csv > '+DIR_IN+FILE_FLUX+'_mod.csv'\n",
    "    os.system(OS_CMD)\n",
    "    \n",
    "    DF_DATA_ALL      = pd.read_csv(DIR_IN+FILE_FLUX+'_mod.csv',converters=CONVERTERS,comment='#')\n",
    "    DF_FLUX          = DF_DATA_ALL[['TIMESTAMP_START','TIMESTAMP_END']+VAR_NAMES]\n",
    "    if DEBUG == 'Y':\n",
    "        print('1: ',DF_FLUX)\n",
    "    \n",
    "    nDATA            = len(DF_FLUX['TIMESTAMP_START'])\n",
    "    INDICES          = []\n",
    "    for iDATA in range(nDATA):\n",
    "        DATE_TIME        = DF_FLUX['TIMESTAMP_START'][iDATA]\n",
    "        IS_MIDNIGHT      = (DATE_TIME.hour, DATE_TIME.minute) == (0,0)\n",
    "        if IS_MIDNIGHT:\n",
    "            print(iDATA, INDICES)\n",
    "            DF_FLUX          = DF_FLUX.drop(index=INDICES)\n",
    "            break\n",
    "        else:\n",
    "            INDICES.append(iDATA)\n",
    "\n",
    "    if DEBUG == 'Y':\n",
    "        print('2: ',iDATA,nDATA)\n",
    "        print(DF_FLUX)\n",
    "    \n",
    "    nDATA            = len(DF_FLUX['TIMESTAMP_END'])\n",
    "    INDICES          = []\n",
    "    for iDATA in range(nDATA-1,0,-1):\n",
    "        TIME             = DF_FLUX['TIMESTAMP_END'][iDATA+1]\n",
    "        IS_MIDNIGHT      = (DATE_TIME.hour, DATE_TIME.minute) == (0,0)\n",
    "        if IS_MIDNIGHT:\n",
    "            print(iDATA, INDICES)\n",
    "            DF_FLUX          = DF_FLUX.drop(index=INDICES)\n",
    "            break\n",
    "        else:\n",
    "            INDICES.append(iDATA)\n",
    "        \n",
    "    if DEBUG == 'Y':\n",
    "        print('3: ',iDATA,nDATA)\n",
    "        print(DF_FLUX)\n",
    "    \n",
    "    DF_FLUX_DAILY    = DF_FLUX.resample('D', on='TIMESTAMP_START').mean()\n",
    "    if DEBUG == 'Y':\n",
    "        print('4: ',DF_FLUX_DAILY)\n",
    "\n",
    "    FILE_OUT         = DIR_OUT+SITE_CODE.replace('-','_')+'-energyandcarbon-dailyUTC_unscaled.dat'\n",
    "    print('Writing to: '+FILE_OUT)\n",
    "    DF_FLUX_DAILY.to_csv(FILE_OUT,header=HEADER,date_format='%Y%m%d')\n",
    "    \n",
    "    #Convert carbon fluxes from micromolCO2 m-2 s-1 to gC m-2 d-1\n",
    "    for iVAR,VAR in enumerate(VAR_NAMES):\n",
    "        if CONV_FACTORS[iVAR] != 1.0:\n",
    "            DF_FLUX_DAILY[VAR] = DF_FLUX_DAILY[VAR]*CONV_FACTORS[iVAR]\n",
    "    \n",
    "    if DEBUG == 'Y':\n",
    "        print('5: ',DF_FLUX_DAILY)\n",
    "\n",
    "    FILE_OUT         = DIR_OUT+SITE_CODE.replace('-','_')+'-energyandcarbon-dailyUTC.dat'\n",
    "    print('Writing to: '+FILE_OUT)\n",
    "    DF_FLUX_DAILY.to_csv(FILE_OUT,header=HEADER,date_format='%Y%m%d')\n",
    "    \n",
    "    # Need to replace TIMESTAMP_START\n",
    "    OS_CMD = \"sed -i '1s/TIMESTAMP_START/# YYYYMMDD UTC/' \"+FILE_OUT\n",
    "    os.system(OS_CMD)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "forced-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Configure for python (.py) or Jupyter notebook\n",
    "\n",
    "    if '-platform' in sys.argv:\n",
    "        ARGLOC        = sys.argv.index('-platform')\n",
    "        TEMP          = sys.argv.pop(ARGLOC)\n",
    "        PLATFORM      = str(sys.argv.pop(ARGLOC))\n",
    "        DEBUG         = sys.argv[1]\n",
    "        INTERACTIVE   = sys.argv[2]\n",
    "        SUITE         = sys.argv[3]\n",
    "        OPTIONS       = sys.argv[4]\n",
    "        PLOT_OPT      = sys.argv[5]\n",
    "        sDIR          = sys.argv[6]\n",
    "        sDATE         = sys.argv[6]\n",
    "    else:\n",
    "        PLATFORM      = 'notebook'\n",
    "        DEBUG         = 'N'\n",
    "        INTERACTIVE   = 'N'\n",
    "        SUITE         = 'u-cr886'\n",
    "        OPTIONS       = 'YYYYYYYY'\n",
    "        PLOT_OPT      = '1'\n",
    "        sDIR          = 'Test'\n",
    "        sDATE         = '20221108'\n",
    "\n",
    "    print('Platform = '+PLATFORM)\n",
    "\n",
    "    # Set directories for the platform selected\n",
    "    if PLATFORM == 'MONSOON':\n",
    "        DIR_HOME     = '/projects/ecobrasil/'\n",
    "        DIR_DATA     = DIR_HOME\n",
    "        DIR_OUT      = DIR_HOME+'ghayma/'\n",
    "    elif PLATFORM == 'CEH' or PLATFORM == 'notebook':\n",
    "        DIR_HOME     = '/data/grp/eow/garr/'\n",
    "        DIR_DATA     = DIR_HOME+'Projects/MotherShip/Data/'\n",
    "        #DIR_OUT      = DIR_HOME+'Projects/MotherShip/Output/'+SUITE+'/'\n",
    "        DIR_OUT      = '/users/eow/garr/roses/'+SUITE+'/'\n",
    "        DIR_FLUX     = '/prj/MOYA/JULES/DEPOSITION/SITE/FLUXNET/DATA/testvn1.4/'\n",
    "\n",
    "    DIR_PLOTS    = os.path.join(DIR_OUT, 'PLOTS/'+SUITE+'/')\n",
    "    #SITE_CODES   = ['AT-Neu','FI-Hyy','UK-AMo','UK-Ham','US-Ne1','ZA-Kru']\n",
    "    SITE_CODES   = ['UK-AMo', 'UK-Ham', 'UK-MrH', 'UK-Rdm', 'UK-Tad', 'CH-Oe1']\n",
    "    SITES_INFO_UK= ['UK-MrH', 'UK-Rdm', 'UK-Tad']\n",
    "    \n",
    "    if not os.path.exists(DIR_OUT):\n",
    "        os.system('mkdir -p '+DIR_OUT)\n",
    "\n",
    "    # get site meta data\n",
    "    SITE_DATA     = get_site_metadata(DIR=DIR_DATA, SITE_CODES=SITE_CODES, DEBUG=DEBUG)\n",
    "    SITE_DATA_ALL = get_site_metadata(DIR=DIR_DATA, SITE_CODES=ALL_SITE_CODES, DEBUG=DEBUG)\n",
    "    if DEBUG == 'Y':\n",
    "        print(''); print('SITE_DATA:'); print(SITE_DATA)\n",
    "\n",
    "    if OPTIONS[0] == 'Y':\n",
    "        output_var_info(DIR_OUT, ALL_SITE_CODES, SITES_INFO_UK, SITE_DATA_ALL, DEBUG)    \n",
    "\n",
    "    if OPTIONS[4] == 'Y':\n",
    "        GRID_VARS_OUT = ['eastings', 'northings', 'latitude', 'longitude' ]\n",
    "        SOIL_VARS_OUT = ['b', 'sathh', 'satcon', 'sm_sat', 'sm_crit', 'sm_wilt', 'hcap', 'hcon', 'albsoil', 'clay' ]\n",
    "        SOIL_MODELS = ['BC', 'VG']\n",
    "        DATA_SOIL   = { VAR:0.0 for VAR in SOIL_MODELS}\n",
    "\n",
    "        for SOIL_MODEL in SOIL_MODELS:\n",
    "            DATA_SOIL[SOIL_MODEL] = input_ancil_soil_uk(SOIL_MODEL, GRID_VARS_OUT+SOIL_VARS_OUT, DEBUG)\n",
    "\n",
    "    if OPTIONS[5] == 'Y':\n",
    "        TOP_VARS      = ['latitude', 'longitude', 'field900', 'field900_1' ]\n",
    "        DATA_TOP      = input_ancil_top(TOP_VARS, DEBUG)\n",
    "\n",
    "    # Loop over selected sites\n",
    "    for SITE_CODE in SITE_CODES:\n",
    "\n",
    "        print(\"\"); print(\"Writing namelists for site: \"+SITE_CODE)\n",
    "        \n",
    "        if OPTIONS[1] == 'Y':\n",
    "            # output ancil namelists \n",
    "            output_namelist_ancil(DIR_OUT, SITE_CODE, SITE_DATA, DEBUG)\n",
    "\n",
    "        if OPTIONS[2] == 'Y':\n",
    "            # output drive namelists \n",
    "            output_namelist_drive(DIR_OUT, SITE_CODE, SITE_DATA, DEBUG)\n",
    "\n",
    "        if OPTIONS[3] == 'Y':\n",
    "            if int(SITE_DATA[SITE_CODE]['presc_data']) >= 1:\n",
    "                # output prescribed data namelist: sthuf \n",
    "                output_namelist_presc_sthuf(DIR_OUT, SITE_CODE, SITE_DATA, DEBUG)\n",
    "\n",
    "            if int(SITE_DATA[SITE_CODE]['presc_data']) >= 2:\n",
    "                # output prescribed data namelists \n",
    "                output_namelist_presc_lai(DIR_OUT, SITE_CODE, SITE_DATA, DEBUG)\n",
    "\n",
    "        if OPTIONS[4] == 'Y' and 'UK' in SITE_CODE:\n",
    "            \n",
    "            # output files with ancillary soil parameters\n",
    "            for SOIL_MODEL in SOIL_MODELS:\n",
    "                output_ancil_soil_uk(DIR_OUT, SITE_CODE, SITE_DATA, \\\n",
    "                                     DATA_SOIL[SOIL_MODEL], SOIL_VARS_OUT, \\\n",
    "                                     SOIL_MODEL.lower(), DEBUG)\n",
    "\n",
    "        if OPTIONS[5] == 'Y':\n",
    "            # output files with ancillary topographic parameters \n",
    "            output_ancil_top(DIR_OUT, SITE_CODE, SITE_DATA, DATA_TOP, TOP_VARS, DEBUG)\n",
    "\n",
    "        if OPTIONS[6] == 'Y':\n",
    "            # output files with met driving data\n",
    "            #get_met_data(DIR_DATA+'FLUX_DATA/Original/', DIR_MET, SITE_CODE, SITE_DATA, DEBUG)\n",
    "            DEBUG = 'N'\n",
    "            if sDIR[0].lower() == 't':   # Write to test folder\n",
    "                DIR_MET_OUT  = DIR_DATA+'FLUX_DATA/Fluxnet_Met/'\n",
    "            else:                        # Write to folder with fluxnet met driving data\n",
    "                DIR_MET_OUT  = DIR_FLUX+'fluxnet/'\n",
    "            get_write_met_data(DIR_DATA+'FLUX_DATA/Original/', DIR_MET_OUT, \\\n",
    "                         SITE_CODE, SITE_DATA, DEBUG)\n",
    "            \n",
    "        if OPTIONS[7] == 'Y':\n",
    "            # output files with flux data\n",
    "            DEBUG = 'N'\n",
    "            DIR_FLUX_SUB = DIR_DATA+'FLUX_DATA/Original/'\n",
    "            \n",
    "            if sDIR[0].lower() == 't':\n",
    "                DIR_FLUX_OUT = DIR_DATA+'FLUX_DATA/Fluxnet_Fluxes/'\n",
    "            else:\n",
    "                DIR_FLUX_OUT = DIR_FLUX+'fluxnet_obs/'\n",
    "\n",
    "            get_write_flux_data_pandas(DIR_FLUX_SUB, DIR_FLUX_OUT, SITE_CODE, SITE_DATA, DEBUG)\n",
    "            #get_write_flux_data_iris(DIR_FLUX_SUB, DIR_FLUX_OUT, SITE_CODE, SITE_DATA, DEBUG)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "amended-projection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform = notebook\n",
      "('Metadata: ', 'UK-AMo', -3.24362, 55.7925, 322032.8869074715, 656163.9504569245)\n",
      "('Metadata: ', 'UK-Ham', -0.8583, 51.153533, 479839.1656206436, 140041.80424263803)\n",
      "('Metadata: ', 'UK-MrH', -2.388234, 54.695035, 374979.71487987146, 533414.4587791847)\n",
      "('Metadata: ', 'UK-Rdm', 0.419533, 52.442948, 564429.5090902135, 285570.23789645004)\n",
      "('Metadata: ', 'UK-Tad', -2.82863998413085, 51.2070999145507, 342119.8809275898, 145704.98805261383)\n",
      "('Metadata: ', 'UK-AMo', -3.24362, 55.7925, 322032.8869074715, 656163.9504569245)\n",
      "('Metadata: ', 'UK-Arn', -6.600454, 58.322834, 130678.7235263362, 946315.3846504791)\n",
      "('Metadata: ', 'UK-Bam', -3.16, 56.93, 329409.0118815397, 782659.7554786149)\n",
      "('Metadata: ', 'UK-BBB', -0.4909216, 53.86104, 499235.4877734799, 441613.9874813196)\n",
      "('Metadata: ', 'UK-BBC', -0.4865083, 53.86088, 499526.0612592405, 441602.37272933696)\n",
      "('Metadata: ', 'UK-BnB', -6.669835, 54.82326, 100106.63367903617, 557610.8270271077)\n",
      "('Metadata: ', 'UK-CLs', -3.9639542, 58.370674, 285135.59549058776, 944108.6356206625)\n",
      "('Metadata: ', 'UK-Cst', -2.773793, 53.84995, 349101.37287237705, 439602.28013366205)\n",
      "('Metadata: ', 'UK-Dke', -3.968809, 58.427264, 285036.1162825463, 950415.423511296)\n",
      "('Metadata: ', 'UK-DkF', -3.9702661, 58.431141, 284963.69504880195, 950849.42909779)\n",
      "('Metadata: ', 'UK-EBu', -3.205777778, 55.866, 324547.6515276393, 664300.7326216032)\n",
      "('Metadata: ', 'UK-Ech', -3.3087757, 57.505657, 321586.59001790005, 846892.2358970186)\n",
      "('Metadata: ', 'UK-EHd', -1.322469, 51.583199, 446938.84835723526, 187419.0664662281)\n",
      "('Metadata: ', 'UK-ESa', -2.85861111, 55.9069444, 346327.6489620397, 668533.083755685)\n",
      "('Metadata: ', 'UK-GaB', -6.529928, 55.10994, 111152.07768079394, 588884.7673202911)\n",
      "('Metadata: ', 'UK-Gnn', -6.760763, 54.96185, 95321.19561707758, 573406.6589656426)\n",
      "('Metadata: ', 'UK-Gri', -3.79805556, 56.6072222, 289641.65823710465, 747581.3055846556)\n",
      "('Metadata: ', 'UK-Gst', -1.240111, 60.230296, 442085.1834415508, 1149735.0645698903)\n",
      "('Metadata: ', 'UK-GtF', -0.192668, 52.470689, 522751.7763846115, 287438.2216070432)\n",
      "('Metadata: ', 'UK-Gwr', -5.988278, 54.85464, 144048.69202077363, 558392.8239216418)\n",
      "('Metadata: ', 'UK-Ham', -0.8583, 51.153533, 479839.1656206436, 140041.80424263803)\n",
      "('Metadata: ', 'UK-Har', -2.037527777, 55.21272222, 397612.35146625136, 590948.0859158806)\n",
      "('Metadata: ', 'UK-Her', -0.476080000400543, 51.7837982177734, 505108.18516878673, 210608.03100109566)\n",
      "('Metadata: ', 'UK-LBT', -0.1389, 51.5215, 529105.7582917628, 181982.13761001406)\n",
      "('Metadata: ', 'UK-Lns', -3.765051, 58.391024, 296826.3964977033, 946051.3159859374)\n",
      "('Metadata: ', 'UK-MrH', -2.388234, 54.695035, 374979.71487987146, 533414.4587791847)\n",
      "('Metadata: ', 'UK-Myg', -2.779574, 53.854618, 348726.8225809141, 440125.7333698787)\n",
      "('Metadata: ', 'UK-PL1', -1.48333001136779, 51.5332984924316, 435833.78944822407, 181778.94239728723)\n",
      "('Metadata: ', 'UK-PL2', -1.23333001136779, 51.4333000183105, 453288.84153860086, 170811.0402524558)\n",
      "('Metadata: ', 'UK-PL3', -1.266666667, 51.45, 450953.15583127347, 172644.37110787374)\n",
      "('Metadata: ', 'UK-Png', -4.068402, 52.422332, 259364.55679043243, 282536.51237018773)\n",
      "('Metadata: ', 'UK-Po1', -0.9139667, 53.45704, 472103.91380296194, 396164.82192593935)\n",
      "('Metadata: ', 'UK-Po2', -0.9082767, 53.45905, 472478.2478808779, 396394.1721743992)\n",
      "('Metadata: ', 'UK-Po3', -0.910275, 53.45659, 472349.7695115729, 396118.50546762726)\n",
      "('Metadata: ', 'UK-Pob', -0.922198, 53.430831, 471601.4979060943, 393241.18238260254)\n",
      "('Metadata: ', 'UK-Rdm', 0.419533, 52.442948, 564429.5090902135, 285570.23789645004)\n",
      "('Metadata: ', 'UK-Rsh', -0.5257917, 53.25981, 498327.19616627134, 374689.9490019827)\n",
      "('Metadata: ', 'UK-Stm', 0.224473, 52.331415, 551556.7978059733, 272741.8015300073)\n",
      "('Metadata: ', 'UK-Swt', -0.259556, 52.435915, 518302.3580063345, 283459.4861928315)\n",
      "('Metadata: ', 'UK-Tad', -2.82863998413085, 51.2070999145507, 342119.8809275898, 145704.98805261383)\n",
      "('Metadata: ', 'UK-WdC', -0.948449, 51.82715, 472459.3368092227, 214853.5728909591)\n",
      "('Metadata: ', 'UK-Wdd', -0.950881, 51.830757, 472285.984302315, 215252.27598548704)\n",
      "('Metadata: ', 'UK-Wot', -0.184811, 52.459926, 523315.4483610449, 286254.6756372095)\n",
      "Writing to /users/eow/garr/roses/u-cr886/var/info.inc\n",
      "\n",
      "Soil parameters: Brooks & Corey\n",
      "eastings\n",
      "[656]\n",
      "northings\n",
      "[1057]\n",
      "latitude\n",
      "[1057  656]\n",
      "longitude\n",
      "[1057  656]\n",
      "b\n",
      "[   4 1057  656]\n",
      "sathh\n",
      "[   4 1057  656]\n",
      "satcon\n",
      "[   4 1057  656]\n",
      "sm_sat\n",
      "[   4 1057  656]\n",
      "sm_crit\n",
      "[   4 1057  656]\n",
      "sm_wilt\n",
      "[   4 1057  656]\n",
      "hcap\n",
      "[   4 1057  656]\n",
      "hcon\n",
      "[   4 1057  656]\n",
      "Albsoil\n",
      "Clay\n",
      "[   4 1057  656]\n",
      "\n",
      "Soil parameters: Van Genuchten\n",
      "eastings\n",
      "[656]\n",
      "northings\n",
      "[1057]\n",
      "latitude\n",
      "[1057  656]\n",
      "longitude\n",
      "[1057  656]\n",
      "b\n",
      "[   4 1057  656]\n",
      "sathh\n",
      "[   4 1057  656]\n",
      "satcon\n",
      "[   4 1057  656]\n",
      "sm_sat\n",
      "[   4 1057  656]\n",
      "sm_crit\n",
      "[   4 1057  656]\n",
      "sm_wilt\n",
      "[   4 1057  656]\n",
      "hcap\n",
      "[   4 1057  656]\n",
      "hcon\n",
      "[   4 1057  656]\n",
      "Albsoil\n",
      "Clay\n",
      "[   4 1057  656]\n",
      "\n",
      "Top Model parameters\n",
      "latitude\n",
      "[145]\n",
      "longitude\n",
      "[192]\n",
      "field900\n",
      "[145 192]\n",
      "field900_1\n",
      "[145 192]\n",
      "\n",
      "Writing namelists for site: UK-AMo\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-ancil-UK_AMo.conf\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-drive-UK_AMo.conf\n",
      "('UK-AMo', 322, 656)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_AMo_soil_from_UKChess_bc.dat\n",
      "('UK-AMo', 322, 656)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_AMo_soil_from_UKChess_vg.dat\n",
      "('UK-AMo', 55.7925, -3.24362, 116, 190, 5.3266602, 1.9720794)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_AMo_TOP.nc\n",
      "*** SUCCESS writing file /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_AMo_TOP.nc\n",
      "\n",
      "Writing namelists for site: UK-Ham\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-ancil-UK_Ham.conf\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-drive-UK_Ham.conf\n",
      "('UK-Ham', 479, 140)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_Ham_soil_from_UKChess_bc.dat\n",
      "('UK-Ham', 479, 140)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_Ham_soil_from_UKChess_vg.dat\n",
      "('UK-Ham', 51.153533, -0.8583, 112, 191, 5.9487453, 2.1236765)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_Ham_TOP.nc\n",
      "*** SUCCESS writing file /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_Ham_TOP.nc\n",
      "\n",
      "Writing namelists for site: UK-MrH\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-ancil-UK_MrH.conf\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-drive-UK_MrH.conf\n",
      "('UK-MrH', 374, 533)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_MrH_soil_from_UKChess_bc.dat\n",
      "('UK-MrH', 374, 533)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_MrH_soil_from_UKChess_vg.dat\n",
      "('UK-MrH', 54.695035, -2.388234, 115, 190, 5.250741, 2.0082104)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_MrH_TOP.nc\n",
      "*** SUCCESS writing file /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_MrH_TOP.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/grp/eow/garr/Utilities/MINICONDA/Miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Met/UK_MrH-met.dat\n",
      "(1, [0])\n",
      "(39451, [])\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Fluxes/UK_MrH-energyandcarbon-dailyUTC_unscaled.dat\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Fluxes/UK_MrH-energyandcarbon-dailyUTC.dat\n",
      "\n",
      "Writing namelists for site: UK-Rdm\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-ancil-UK_Rdm.conf\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-drive-UK_Rdm.conf\n",
      "('UK-Rdm', 564, 285)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_Rdm_soil_from_UKChess_bc.dat\n",
      "('UK-Rdm', 564, 285)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_Rdm_soil_from_UKChess_vg.dat\n",
      "('UK-Rdm', 52.442948, 0.419533, 113, 0, 6.8279514, 2.1487567)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_Rdm_TOP.nc\n",
      "*** SUCCESS writing file /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_Rdm_TOP.nc\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Met/UK_Rdm-met.dat\n",
      "(1, [0])\n",
      "(28573, [])\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Fluxes/UK_Rdm-energyandcarbon-dailyUTC_unscaled.dat\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Fluxes/UK_Rdm-energyandcarbon-dailyUTC.dat\n",
      "\n",
      "Writing namelists for site: UK-Tad\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-ancil-UK_Tad.conf\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-drive-UK_Tad.conf\n",
      "('UK-Tad', 342, 145)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_Tad_soil_from_UKChess_bc.dat\n",
      "('UK-Tad', 342, 145)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/soil/from_UKChess/UK_Tad_soil_from_UKChess_vg.dat\n",
      "('UK-Tad', 51.2070999145507, -2.82863998413085, 112, 190, 5.5945787, 1.7901399)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_Tad_TOP.nc\n",
      "*** SUCCESS writing file /users/eow/garr/roses/u-cr886/ancil/topmodel/UK_Tad_TOP.nc\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Met/UK_Tad-met.dat\n",
      "(1, [0])\n",
      "(86149, [])\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Fluxes/UK_Tad-energyandcarbon-dailyUTC_unscaled.dat\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Fluxes/UK_Tad-energyandcarbon-dailyUTC.dat\n",
      "\n",
      "Writing namelists for site: CH-Oe1\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-ancil-CH_Oe1.conf\n",
      "Writing to /users/eow/garr/roses/u-cr886/app/jules/opt/rose-app-drive-CH_Oe1.conf\n",
      "('CH-Oe1', 47.28583333, 7.731944444, 109, 4, 3.3085103, 2.3867426)\n",
      "Writing to /users/eow/garr/roses/u-cr886/ancil/topmodel/CH_Oe1_TOP.nc\n",
      "*** SUCCESS writing file /users/eow/garr/roses/u-cr886/ancil/topmodel/CH_Oe1_TOP.nc\n",
      "Writing to: /data/grp/eow/garr/Projects/MotherShip/Data/FLUX_DATA/Fluxnet_Met/CH_Oe1-met.dat\n",
      "(0, [])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "122736",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2436fc2ab63a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-634a03e584c1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mDIR_FLUX_OUT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDIR_FLUX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'fluxnet_obs/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mget_write_flux_data_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR_FLUX_SUB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIR_FLUX_OUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSITE_CODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSITE_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;31m#get_write_flux_data_iris(DIR_FLUX_SUB, DIR_FLUX_OUT, SITE_CODE, SITE_DATA, DEBUG)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6e0333b09fd1>\u001b[0m in \u001b[0;36mget_write_flux_data_pandas\u001b[0;34m(DIR_IN, DIR_OUT, SITE_CODE, SITE_DATA, DEBUG)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mINDICES\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miDATA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnDATA\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mTIME\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mDF_FLUX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TIMESTAMP_END'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miDATA\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mIS_MIDNIGHT\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDATE_TIME\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATE_TIME\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIS_MIDNIGHT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/eow/garr/Work/Utilities/MINICONDA/Miniconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/eow/garr/Work/Utilities/MINICONDA/Miniconda2/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 122736"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auchencorth Moss\n",
    "#AURN_Easting,  AURN_Northing   =  322166, 656128\n",
    "#AURN_Latitude, AURN_Longitude  =  55.792160, -3.242900\n",
    "#Easting, Northing = ccrs.OSGB().transform_point( AURN_Longitude, AURN_Latitude, ccrs.PlateCarree() )\n",
    "#print(Easting, Northing, int(Easting/1000), int(Northing/1000))\n",
    "\n",
    "#Yarner Wood\n",
    "AURN_Easting, AURN_Northing    = 278611, 78949\n",
    "AURN_Latitude, AURN_Longitude  =  50.597600, -3.716510\n",
    "Easting, Northing = ccrs.OSGB().transform_point( AURN_Longitude, AURN_Latitude, ccrs.PlateCarree() )\n",
    "print(Easting, Northing, int(Easting/1000), int(Northing/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-meter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTHON3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
